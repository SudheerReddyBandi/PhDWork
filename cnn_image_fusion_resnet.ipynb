{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exdMR73Ci7_C",
        "outputId": "327c4121-d8aa-4818-d86f-63447b18b92e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6ffnGDcjXOv"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"drive/My Drive/Data4.zip\",\"r\") as zip_ref:\n",
        "  zip_ref.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eY0IAErBjY76",
        "outputId": "32099e57-8edd-4a7d-9841-e60df1e79d2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/10772 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/keras/utils/image_utils.py:409: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
            "  warnings.warn(\n",
            "100%|██████████| 10772/10772 [00:05<00:00, 1867.59it/s]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing import image\n",
        "import keras.utils as image\n",
        "from keras import utils as np_utils\n",
        "%matplotlib inline\n",
        "train = pd.read_csv('drive/My Drive/Traindata18.csv')\n",
        "TRAIN_PATH ='Data4/Newdata/'\n",
        "from PIL import Image\n",
        "from imageio import imread\n",
        "from skimage.transform import resize\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "# defining a function to read images\n",
        "def read_img(img_path):\n",
        "  img = tf.keras.utils.load_img(img_path, target_size=[64,64,1],grayscale=True)\n",
        "  img = img.convert(mode='RGB') #makes 3 channels\n",
        "  img = image.img_to_array(img)\n",
        "  img = img/255\n",
        "  return img\n",
        "# reading the images\n",
        "train_img = []\n",
        "for img_path in tqdm(train.Image.values):\n",
        "  train_img.append(read_img(TRAIN_PATH + img_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROrrqWlQjY54",
        "outputId": "617cab81-c6b3-4a0d-f160-e7cb524ca3ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of total input: 10772\n",
            "(8617, 64, 64, 3) (2155, 64, 64, 3)\n",
            "(8617, 10) (2155, 10)\n",
            "2155\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "from keras import utils as np_utils\n",
        "X_train = np.array(train_img)\n",
        "print(\"Length of total input:\",len(X_train))\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "lb = LabelEncoder()\n",
        "lb.fit(train.Label.values)\n",
        "Y_train = lb.transform(train.Label.values)\n",
        "Y_train=Y_train.astype(np.int32)\n",
        "Y_train = keras.utils.np_utils.to_categorical(Y_train)\n",
        "split_size = int(X_train.shape[0]*0.8)\n",
        "x_train, x_test = X_train[:split_size], X_train[split_size:]\n",
        "y_train, y_test = Y_train[:split_size], Y_train[split_size:]\n",
        "print(x_train.shape, x_test.shape,)\n",
        "print(y_train.shape, y_test.shape)\n",
        "print(len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sL1QjTEjY2W",
        "outputId": "f84928a7-9655-4df5-a457-edc60042c201"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "Number of training examples = 8617\n",
            "Number of testing examples = 2155\n",
            "Image data shape = (64, 64, 3)\n",
            "Number of classes = 10\n"
          ]
        }
      ],
      "source": [
        "print(y_test[1:5])\n",
        "image_shape = x_train.shape[1:]\n",
        "n_classes = y_train.shape[1]\n",
        "print(\"Number of training examples =\", x_train.shape[0])\n",
        "print(\"Number of testing examples =\", x_test.shape[0])\n",
        "print(\"Image data shape =\", image_shape)\n",
        "print(\"Number of classes =\", n_classes)\n",
        "img_rows, img_cols = 64, 64\n",
        "input_shape = (img_rows, img_cols, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gp-EFPDdk5rS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import keras.utils\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.regularizers import l1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5k9mrXT6jYzo",
        "outputId": "d49811fe-aa36-4353-f9d1-3a57db1b6b26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 2, 2, 2048)        23587712  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1024)              8389632   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,636,042\n",
            "Trainable params: 32,582,922\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Build the model\n",
        "from keras.applications.resnet import ResNet50\n",
        "\n",
        "'The first base model used is VGG19. The pretrained weights from the imagenet challenge are used'\n",
        "#base_model_1 = VGG19(include_top=False,weights='imagenet',input_shape=(64,64,3),classes=n_classes)\n",
        "\n",
        "'For the 2nd base model we will use Resnet 50 and compare the performance against the previous one.The hypothesis is that Resnet 50 should perform better because of its deeper architecture'\n",
        "base_model_1 = ResNet50(include_top=False,weights='imagenet',input_shape=(64,64,3),classes=n_classes)\n",
        "\n",
        "#Lets add the final layers to these base models where the actual classification is done in the dense layers\n",
        "\n",
        "model_1= Sequential()\n",
        "model_1.add(base_model_1) #Adds the base model (in this case vgg19 to model_1)\n",
        "model_1.add(Flatten()) #Since the output before the flatten layer is a matrix we have to use this function to get a vector of the form nX1 to feed it into the fully connected layers\n",
        "\n",
        "#Add the Dense layers along with activation and batch normalization\n",
        "model_1.add(Dense(1024,activation=('relu'),input_dim=512))\n",
        "model_1.add(Dense(512,activation=('relu')))\n",
        "model_1.add(Dense(256,activation=('relu')))\n",
        "#model_1.add(Dropout(.3))#Adding a dropout layer that will randomly drop 30% of the weights\n",
        "\n",
        "#model_1.add(Dropout(.2))\n",
        "\n",
        "model_1.add(Dense(10,activation=('softmax'))) #This is the classification layer\n",
        "\n",
        "#Check final model summary\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nymM5uojYwp",
        "outputId": "d429d76c-4a26-4548-caa1-021b4c33801c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "270/270 [==============================] - 55s 73ms/step - loss: 0.2441 - accuracy: 0.9307 - val_loss: 142.1959 - val_accuracy: 0.1044\n",
            "Epoch 2/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0662 - accuracy: 0.9799 - val_loss: 6.5412 - val_accuracy: 0.0812\n",
            "Epoch 3/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0598 - accuracy: 0.9863 - val_loss: 4.6217 - val_accuracy: 0.2190\n",
            "Epoch 4/100\n",
            "270/270 [==============================] - 17s 62ms/step - loss: 0.0374 - accuracy: 0.9890 - val_loss: 0.5922 - val_accuracy: 0.8478\n",
            "Epoch 5/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0247 - accuracy: 0.9925 - val_loss: 0.0947 - val_accuracy: 0.9735\n",
            "Epoch 6/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0711 - accuracy: 0.9826 - val_loss: 0.0957 - val_accuracy: 0.9722\n",
            "Epoch 7/100\n",
            "270/270 [==============================] - 17s 62ms/step - loss: 0.0308 - accuracy: 0.9920 - val_loss: 0.0352 - val_accuracy: 0.9884\n",
            "Epoch 8/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0272 - accuracy: 0.9926 - val_loss: 0.0280 - val_accuracy: 0.9935\n",
            "Epoch 9/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0209 - accuracy: 0.9938 - val_loss: 0.0191 - val_accuracy: 0.9958\n",
            "Epoch 10/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0262 - accuracy: 0.9938 - val_loss: 0.0248 - val_accuracy: 0.9940\n",
            "Epoch 11/100\n",
            "270/270 [==============================] - 17s 62ms/step - loss: 0.0237 - accuracy: 0.9949 - val_loss: 0.0314 - val_accuracy: 0.9921\n",
            "Epoch 12/100\n",
            "270/270 [==============================] - 17s 62ms/step - loss: 0.0337 - accuracy: 0.9929 - val_loss: 0.0220 - val_accuracy: 0.9935\n",
            "Epoch 13/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0257 - accuracy: 0.9923 - val_loss: 0.0376 - val_accuracy: 0.9921\n",
            "Epoch 14/100\n",
            "270/270 [==============================] - 17s 62ms/step - loss: 0.0177 - accuracy: 0.9957 - val_loss: 0.0497 - val_accuracy: 0.9884\n",
            "Epoch 15/100\n",
            "270/270 [==============================] - 17s 62ms/step - loss: 0.0314 - accuracy: 0.9927 - val_loss: 0.0607 - val_accuracy: 0.9842\n",
            "Epoch 16/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0444 - accuracy: 0.9918 - val_loss: 0.0254 - val_accuracy: 0.9935\n",
            "Epoch 17/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0282 - accuracy: 0.9927 - val_loss: 0.0216 - val_accuracy: 0.9944\n",
            "Epoch 18/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0281 - accuracy: 0.9926 - val_loss: 0.0358 - val_accuracy: 0.9898\n",
            "Epoch 19/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0153 - accuracy: 0.9955 - val_loss: 0.0276 - val_accuracy: 0.9944\n",
            "Epoch 20/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0202 - accuracy: 0.9956 - val_loss: 0.0140 - val_accuracy: 0.9944\n",
            "Epoch 21/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0126 - accuracy: 0.9965 - val_loss: 0.0352 - val_accuracy: 0.9935\n",
            "Epoch 22/100\n",
            "270/270 [==============================] - 17s 62ms/step - loss: 0.0171 - accuracy: 0.9952 - val_loss: 0.0461 - val_accuracy: 0.9893\n",
            "Epoch 23/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0194 - accuracy: 0.9945 - val_loss: 0.0352 - val_accuracy: 0.9921\n",
            "Epoch 24/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0204 - accuracy: 0.9941 - val_loss: 0.0190 - val_accuracy: 0.9963\n",
            "Epoch 25/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0108 - accuracy: 0.9973 - val_loss: 0.0138 - val_accuracy: 0.9963\n",
            "Epoch 26/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0271 - accuracy: 0.9936 - val_loss: 0.0507 - val_accuracy: 0.9828\n",
            "Epoch 27/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 0.0423 - val_accuracy: 0.9903\n",
            "Epoch 28/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0129 - accuracy: 0.9968 - val_loss: 0.0110 - val_accuracy: 0.9977\n",
            "Epoch 29/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0266 - accuracy: 0.9933 - val_loss: 0.0183 - val_accuracy: 0.9949\n",
            "Epoch 30/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0378 - accuracy: 0.9918 - val_loss: 0.1435 - val_accuracy: 0.9740\n",
            "Epoch 31/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0435 - accuracy: 0.9905 - val_loss: 0.0960 - val_accuracy: 0.9819\n",
            "Epoch 32/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0158 - accuracy: 0.9964 - val_loss: 0.0178 - val_accuracy: 0.9944\n",
            "Epoch 33/100\n",
            "270/270 [==============================] - 17s 62ms/step - loss: 0.0317 - accuracy: 0.9942 - val_loss: 0.0254 - val_accuracy: 0.9921\n",
            "Epoch 34/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0230 - accuracy: 0.9943 - val_loss: 0.0106 - val_accuracy: 0.9968\n",
            "Epoch 35/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0112 - accuracy: 0.9972 - val_loss: 0.0173 - val_accuracy: 0.9958\n",
            "Epoch 36/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0145 - val_accuracy: 0.9954\n",
            "Epoch 37/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.0211 - val_accuracy: 0.9958\n",
            "Epoch 38/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.0262 - val_accuracy: 0.9963\n",
            "Epoch 39/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0226 - accuracy: 0.9950 - val_loss: 0.5016 - val_accuracy: 0.9643\n",
            "Epoch 40/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0230 - accuracy: 0.9948 - val_loss: 0.0254 - val_accuracy: 0.9921\n",
            "Epoch 41/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 0.0260 - val_accuracy: 0.9930\n",
            "Epoch 42/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.3435 - val_accuracy: 0.9452\n",
            "Epoch 43/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0227 - accuracy: 0.9954 - val_loss: 0.0098 - val_accuracy: 0.9972\n",
            "Epoch 44/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0091 - accuracy: 0.9978 - val_loss: 0.0150 - val_accuracy: 0.9958\n",
            "Epoch 45/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0113 - accuracy: 0.9978 - val_loss: 0.0523 - val_accuracy: 0.9893\n",
            "Epoch 46/100\n",
            "270/270 [==============================] - 17s 62ms/step - loss: 0.0148 - accuracy: 0.9970 - val_loss: 0.0411 - val_accuracy: 0.9930\n",
            "Epoch 47/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0035 - accuracy: 0.9986 - val_loss: 0.0430 - val_accuracy: 0.9940\n",
            "Epoch 48/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0156 - accuracy: 0.9968 - val_loss: 0.0182 - val_accuracy: 0.9958\n",
            "Epoch 49/100\n",
            "270/270 [==============================] - 17s 62ms/step - loss: 0.0132 - accuracy: 0.9959 - val_loss: 0.0147 - val_accuracy: 0.9968\n",
            "Epoch 50/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0109 - accuracy: 0.9979 - val_loss: 0.0128 - val_accuracy: 0.9968\n",
            "Epoch 51/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0120 - accuracy: 0.9977 - val_loss: 0.0336 - val_accuracy: 0.9916\n",
            "Epoch 52/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0137 - accuracy: 0.9972 - val_loss: 0.0206 - val_accuracy: 0.9954\n",
            "Epoch 53/100\n",
            "270/270 [==============================] - 17s 62ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0179 - val_accuracy: 0.9968\n",
            "Epoch 54/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.0339 - val_accuracy: 0.9935\n",
            "Epoch 55/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.0124 - val_accuracy: 0.9958\n",
            "Epoch 56/100\n",
            "270/270 [==============================] - 17s 62ms/step - loss: 0.0180 - accuracy: 0.9973 - val_loss: 0.0411 - val_accuracy: 0.9870\n",
            "Epoch 57/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0325 - accuracy: 0.9947 - val_loss: 0.1032 - val_accuracy: 0.9833\n",
            "Epoch 58/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0340 - accuracy: 0.9938 - val_loss: 0.0317 - val_accuracy: 0.9907\n",
            "Epoch 59/100\n",
            "270/270 [==============================] - 17s 62ms/step - loss: 0.0189 - accuracy: 0.9957 - val_loss: 0.0235 - val_accuracy: 0.9944\n",
            "Epoch 60/100\n",
            "270/270 [==============================] - 17s 62ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.0319 - val_accuracy: 0.9935\n",
            "Epoch 61/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0100 - accuracy: 0.9979 - val_loss: 0.0207 - val_accuracy: 0.9930\n",
            "Epoch 62/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0117 - accuracy: 0.9973 - val_loss: 0.0183 - val_accuracy: 0.9940\n",
            "Epoch 63/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.0185 - val_accuracy: 0.9958\n",
            "Epoch 64/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0071 - accuracy: 0.9987 - val_loss: 0.0107 - val_accuracy: 0.9968\n",
            "Epoch 65/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0253 - accuracy: 0.9955 - val_loss: 0.0148 - val_accuracy: 0.9968\n",
            "Epoch 66/100\n",
            "270/270 [==============================] - 17s 62ms/step - loss: 0.0113 - accuracy: 0.9976 - val_loss: 0.0098 - val_accuracy: 0.9954\n",
            "Epoch 67/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.0128 - val_accuracy: 0.9958\n",
            "Epoch 68/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0090 - accuracy: 0.9983 - val_loss: 0.0175 - val_accuracy: 0.9954\n",
            "Epoch 69/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.0166 - val_accuracy: 0.9949\n",
            "Epoch 70/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0383 - accuracy: 0.9954 - val_loss: 10.1826 - val_accuracy: 0.7480\n",
            "Epoch 71/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0247 - accuracy: 0.9938 - val_loss: 0.0560 - val_accuracy: 0.9865\n",
            "Epoch 72/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0172 - accuracy: 0.9948 - val_loss: 0.0500 - val_accuracy: 0.9884\n",
            "Epoch 73/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.0326 - val_accuracy: 0.9944\n",
            "Epoch 74/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0230 - val_accuracy: 0.9944\n",
            "Epoch 75/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0267 - val_accuracy: 0.9958\n",
            "Epoch 76/100\n",
            "270/270 [==============================] - 17s 62ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.0202 - val_accuracy: 0.9949\n",
            "Epoch 77/100\n",
            "270/270 [==============================] - 17s 62ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.0257 - val_accuracy: 0.9944\n",
            "Epoch 78/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0255 - val_accuracy: 0.9954\n",
            "Epoch 79/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 0.0635 - val_accuracy: 0.9819\n",
            "Epoch 80/100\n",
            "270/270 [==============================] - 17s 62ms/step - loss: 0.0092 - accuracy: 0.9978 - val_loss: 0.0500 - val_accuracy: 0.9944\n",
            "Epoch 81/100\n",
            "270/270 [==============================] - 17s 62ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0572 - val_accuracy: 0.9861\n",
            "Epoch 82/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0131 - accuracy: 0.9971 - val_loss: 0.0517 - val_accuracy: 0.9870\n",
            "Epoch 83/100\n",
            "270/270 [==============================] - 17s 62ms/step - loss: 0.0152 - accuracy: 0.9973 - val_loss: 0.0923 - val_accuracy: 0.9773\n",
            "Epoch 84/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0117 - accuracy: 0.9974 - val_loss: 0.0342 - val_accuracy: 0.9940\n",
            "Epoch 85/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0115 - accuracy: 0.9976 - val_loss: 0.0380 - val_accuracy: 0.9903\n",
            "Epoch 86/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0109 - accuracy: 0.9978 - val_loss: 0.0203 - val_accuracy: 0.9944\n",
            "Epoch 87/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 0.0216 - val_accuracy: 0.9958\n",
            "Epoch 88/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.0212 - val_accuracy: 0.9968\n",
            "Epoch 89/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 5.3814e-04 - accuracy: 0.9999 - val_loss: 0.0181 - val_accuracy: 0.9963\n",
            "Epoch 90/100\n",
            "270/270 [==============================] - 17s 62ms/step - loss: 0.0104 - accuracy: 0.9981 - val_loss: 0.0375 - val_accuracy: 0.9921\n",
            "Epoch 91/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.0239 - val_accuracy: 0.9935\n",
            "Epoch 92/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0358 - val_accuracy: 0.9926\n",
            "Epoch 93/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.0296 - val_accuracy: 0.9935\n",
            "Epoch 94/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 0.0337 - val_accuracy: 0.9921\n",
            "Epoch 95/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.0451 - val_accuracy: 0.9921\n",
            "Epoch 96/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.0299 - val_accuracy: 0.9940\n",
            "Epoch 97/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.0347 - val_accuracy: 0.9921\n",
            "Epoch 98/100\n",
            "270/270 [==============================] - 17s 62ms/step - loss: 0.0136 - accuracy: 0.9970 - val_loss: 0.0797 - val_accuracy: 0.9916\n",
            "Epoch 99/100\n",
            "270/270 [==============================] - 17s 64ms/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 0.0741 - val_accuracy: 0.9824\n",
            "Epoch 100/100\n",
            "270/270 [==============================] - 17s 63ms/step - loss: 0.0133 - accuracy: 0.9976 - val_loss: 0.0249 - val_accuracy: 0.9940\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "model_1.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=Adam( learning_rate=0.0001,amsgrad=False,name=\"Adam\",),metrics=['accuracy'])\n",
        "history3 = model_1.fit(x_train, y_train, batch_size=32, epochs=100, verbose=1, validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6DQfLHj3MQE"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s29A6dbzjYt2"
      },
      "outputs": [],
      "source": [
        "loss, accuracy=model_1.evaluate(x_test, y_test, verbose=0)\n",
        "print(accuracy*100)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyiyYo5ijYqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aaf97ff-b300-4be2-8e3f-d173a3e82145"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing import image\n",
        "from keras import utils as np_utils\n",
        "%matplotlib inline\n",
        "train = pd.read_csv('drive/My Drive/Traindata18.csv')\n",
        "TRAIN_PATH ='Data4/Newdata/'\n",
        "from PIL import Image\n",
        "from imageio import imread\n",
        "from skimage.transform import resize\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "# defining a function to read images\n",
        "def read_img(img_path):\n",
        "  img = image.load_img(img_path, target_size=[64,64,1],grayscale=True)\n",
        "  img = img.convert(mode='RGB') #makes 3 channels\n",
        "  img = image.img_to_array(img)\n",
        "  img = img/255\n",
        "  return img\n",
        "# reading the images\n",
        "train_img = []\n",
        "for img_path in tqdm(train.Image.values):\n",
        "  train_img.append(read_img(TRAIN_PATH + img_path))"
      ],
      "metadata": {
        "id": "hkTCipxG0hvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import utils as np_utils\n",
        "X_train = np.array(train_img)\n",
        "print(\"Length of total input:\",len(X_train))\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "lb = LabelEncoder()\n",
        "lb.fit(train.Label.values)\n",
        "Y_train = lb.transform(train.Label.values)\n",
        "Y_train=Y_train.astype(np.int32)\n",
        "Y_train = keras.utils.np_utils.to_categorical(Y_train)\n",
        "split_size = int(X_train.shape[0]*0.8)\n",
        "x_train, x_test = X_train[:split_size], X_train[split_size:]\n",
        "y_train, y_test = Y_train[:split_size], Y_train[split_size:]\n",
        "print(x_train.shape, x_test.shape,)\n",
        "print(y_train.shape, y_test.shape)\n",
        "print(len(y_test))"
      ],
      "metadata": {
        "id": "ViiOc0wg0uGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test[1:5])\n",
        "image_shape = x_train.shape[1:]\n",
        "n_classes = y_train.shape[1]\n",
        "print(\"Number of training examples =\", x_train.shape[0])\n",
        "print(\"Number of testing examples =\", x_test.shape[0])\n",
        "print(\"Image data shape =\", image_shape)\n",
        "print(\"Number of classes =\", n_classes)\n",
        "img_rows, img_cols = 64, 64\n",
        "input_shape = (img_rows, img_cols, 1)"
      ],
      "metadata": {
        "id": "VK-cyur_0z-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44opyzojjYkd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#reading dataset using pandas\n",
        "data_test = pd.read_csv('/content/drive/MyDrive/TestSAR.csv')\n",
        "data_train = pd.read_csv('/content/drive/MyDrive/TrainSAR.csv')\n",
        "\n",
        "\n",
        "img_rows, img_cols = 64, 64\n",
        "input_shape = (img_rows, img_cols)\n",
        "#taking the pixel values from the training data. The pixel values start from location 1 in the csv file till the 4096\n",
        "X = np.array(data_train.iloc[:, 1:])\n",
        "#convert the label type to the string value\n",
        "y = to_categorical(np.array(data_train.iloc[:, 0]).astype('str'))\n",
        "\n",
        "#Here we split validation data to optimiza classifier during training\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=13)\n",
        "\n",
        "#Test data\n",
        "X_test = np.array(data_test.iloc[:, 1:])\n",
        "#one hot encoding\n",
        "y_test = to_categorical(np.array(data_test.iloc[:, 0]))\n",
        "\n",
        "\n",
        "#X_train.shape=(number of images in the index 0, rowsize, columnsize)\n",
        "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols)\n",
        "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols)\n",
        "X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols)\n",
        "X_train = np.stack((X_train,)*3,axis=-1) #makes 3 channels\n",
        "X_test = np.stack((X_test,)*3,axis=-1)\n",
        "X_val = np.stack((X_val,)*3,axis=-1)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_val = X_val.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "X_val /= 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEafxppyjYh1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db1321f7-cf44-476a-8c79-70f4d0c18b54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(22531, 64, 64, 3)\n",
            "(9390, 64, 64, 3)\n",
            "(5633, 64, 64, 3)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RINNPDrjYeO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b08f38eb-9556-49af-bd9e-a73d0d67c7f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 2, 2, 2048)        23587712  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              8389632   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,636,042\n",
            "Trainable params: 32,582,922\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Build the model\n",
        "from keras.applications.resnet import ResNet50\n",
        "import keras\n",
        "import keras.utils\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.regularizers import l1\n",
        "\n",
        "'The first base model used is VGG19. The pretrained weights from the imagenet challenge are used'\n",
        "#base_model_1 = VGG19(include_top=False,weights='imagenet',input_shape=(64,64,3),classes=n_classes)\n",
        "\n",
        "'For the 2nd base model we will use Resnet 50 and compare the performance against the previous one.The hypothesis is that Resnet 50 should perform better because of its deeper architecture'\n",
        "base_model_1 = ResNet50(include_top=False,weights='imagenet',input_shape=(64,64,3),classes=10)\n",
        "\n",
        "#Lets add the final layers to these base models where the actual classification is done in the dense layers\n",
        "\n",
        "model_1= Sequential()\n",
        "model_1.add(base_model_1) #Adds the base model (in this case vgg19 to model_1)\n",
        "model_1.add(Flatten()) #Since the output before the flatten layer is a matrix we have to use this function to get a vector of the form nX1 to feed it into the fully connected layers\n",
        "\n",
        "#Add the Dense layers along with activation and batch normalization\n",
        "model_1.add(Dense(1024,activation=('relu'),input_dim=512))\n",
        "model_1.add(Dense(512,activation=('relu')))\n",
        "model_1.add(Dense(256,activation=('relu')))\n",
        "#model_1.add(Dropout(.3))#Adding a dropout layer that will randomly drop 30% of the weights\n",
        "\n",
        "#model_1.add(Dropout(.2))\n",
        "model_1.add(Dense(10,activation=('softmax'))) #This is the classification layer\n",
        "\n",
        "#Check final model summary\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIbCJpncjYbA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "outputId": "48f9a19d-2204-4027-9bf6-0dbe64a91528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "705/705 [==============================] - 94s 71ms/step - loss: 0.6281 - accuracy: 0.8047 - val_loss: 31.0355 - val_accuracy: 0.0501\n",
            "Epoch 2/100\n",
            "705/705 [==============================] - 46s 65ms/step - loss: 0.1820 - accuracy: 0.9416 - val_loss: 0.4768 - val_accuracy: 0.8619\n",
            "Epoch 3/100\n",
            "705/705 [==============================] - 46s 65ms/step - loss: 0.1103 - accuracy: 0.9637 - val_loss: 0.1741 - val_accuracy: 0.9529\n",
            "Epoch 4/100\n",
            "705/705 [==============================] - 46s 65ms/step - loss: 0.0733 - accuracy: 0.9764 - val_loss: 0.1451 - val_accuracy: 0.9608\n",
            "Epoch 5/100\n",
            "705/705 [==============================] - 46s 66ms/step - loss: 0.0518 - accuracy: 0.9838 - val_loss: 0.1477 - val_accuracy: 0.9626\n",
            "Epoch 6/100\n",
            "705/705 [==============================] - 46s 66ms/step - loss: 0.0402 - accuracy: 0.9875 - val_loss: 0.1740 - val_accuracy: 0.9561\n",
            "Epoch 7/100\n",
            "169/705 [======>.......................] - ETA: 30s - loss: 0.0312 - accuracy: 0.9904"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-2565b77ac020>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     name=\"Adam\",),\n\u001b[1;32m      9\u001b[0m                metrics=['accuracy'])\n\u001b[0;32m---> 10\u001b[0;31m history3 = model_1.fit(X_train, y_train,\n\u001b[0m\u001b[1;32m     11\u001b[0m           batch_size=32, epochs=100, verbose=1, validation_data=(X_test, y_test))\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "model_1.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=Adam( learning_rate=0.00001,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.9,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=False,\n",
        "    name=\"Adam\",),\n",
        "               metrics=['accuracy'])\n",
        "history3 = model_1.fit(X_train, y_train,\n",
        "          batch_size=32, epochs=100, verbose=1, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qy9IPI7kjYXd"
      },
      "outputs": [],
      "source": [
        "loss, accuracy=model_1.evaluate(x_test, y_test, verbose=0)\n",
        "print(accuracy*100)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import os\n",
        "import pickle\n",
        "model_1.save('Model_Texture_Resnet.h5')\n",
        "save_history(history3, 'hist1.bin')\n",
        "history=load_history('hist1.bin')\n",
        "plot_compare(history)"
      ],
      "metadata": {
        "id": "lH4PktLKwzgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zkxtn3maw0Oa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}